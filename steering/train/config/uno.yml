---

name: uno_1
odir: training

device: cpu

---

dataset:
  train:
    name: train128
    odir: /scratch/users/rfuchs/packages/tile-nifty/tests/data/files
    dtype: float32
    size: 100
  valid:
    _128:
      name: valid128
      odir: /scratch/users/rfuchs/packages/tile-nifty/tests/data/files
      dtype: float32
      size: 10
    # _256:
    #   name: valid256
    #   odir: /scratch/users/rfuchs/packages/tile-nifty/tests/data/files
    #   dtype: float32
    #   size: 100
  transform:
    log: true
    normalize: true
    standardize: false
    rotate: true
    flip: true
  coordinates: true

dataloader:
  train:
    batch_size: 32
    shuffle: true
    num_workers: 0
    pin_memory: true
  test:
    128:
      batch_size: 32
      num_workers: 0
      shuffle: false
      pin_memory: true

model:
  in_channels: 3
  out_channels: 2
  hidden_channels: 64
  projection_channels: 64
  positional_embedding: null
  uno_out_channels: [32] #,64,64,64,32],
  uno_n_modes: [[16,16]] #,[8,8],[8,8],[8,8],[16,16]],
  uno_scalings: [[1.0,1.0]] #,[0.5,0.5],[1,1],[2,2],[1,1]],
  horizontal_skips_map: null
  channel_mlp_skip: linear
  n_layers: 1
  domain_padding: 0.2

# optimizer:
#   name: AdamW
#   lr: 8.e-3
#   weight_decay: 1.e-4

# scheduler:
#   name: CosineAnnealingLR

# loss:
#   train:
#     name: BCEwithLogitsLoss
#   test:
#     name: BCEwithLogitsLoss

trainer:
  n_epochs: 100
  wandb_log: False
  eval_interval: 5
  use_distributed: False
  verbose: True

---

# plot:
#   n_copies: 10
#   space: True
#   label: True
#   cmap: inferno
#   norm: [log, linear, linear]
